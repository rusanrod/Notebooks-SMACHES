{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962fe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import smach\n",
    "import rospy\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from std_srvs.srv import Empty\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "import tf2_ros as tf2\n",
    "from tf2_sensor_msgs.tf2_sensor_msgs import do_transform_cloud\n",
    "from utils_takeshi import *\n",
    "from grasp_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d65d9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1668796343.004036671]: Link hand_l_finger_vacuum_frame has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796343.006383687]: Link head_l_stereo_camera_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796343.006427710]: Link head_r_stereo_camera_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796343.007314420]: Group state 'neutral' doesn't specify all group joints in group 'arm'. wrist_ft_sensor_frame_joint is missing.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796343.007353012]: Group state 'go' doesn't specify all group joints in group 'arm'. wrist_ft_sensor_frame_joint is missing.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796353.533832227]: Kinematics solver doesn't support #attempts anymore, but only a timeout.\n",
      "Please remove the parameter '/robot_description_kinematics/arm/kinematics_solver_attempts' from your configuration.\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796362.251456083]: IK plugin for group 'whole_body' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796363.029114781]: IK plugin for group 'whole_body_weighted' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n",
      "\u001b[33m[ WARN] [1668796364.419967303]: IK plugin for group 'whole_body_light' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "    global head, wb, arm, tf_man, gaze, robot, scene, calibrate_wrist #wbw, wbl\n",
    "    global rgbd, hand_cam, wrist, gripper, grasp_base, clear_octo_client, service_client, AR_starter, AR_stopper\n",
    "\n",
    "    moveit_commander.roscpp_initialize(sys.argv)\n",
    "    rospy.init_node('pruebas_de_placeo')\n",
    "\n",
    "    head = moveit_commander.MoveGroupCommander('head')\n",
    "    wb = moveit_commander.MoveGroupCommander('whole_body')\n",
    "    arm =  moveit_commander.MoveGroupCommander('arm')\n",
    "    # wbl = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "    #wbw.set_workspace([-6.0, -6.0, 6.0, 6.0]) \n",
    "    #wbl.set_workspace([-6.0, -6.0, 6.0, 6.0])  \n",
    "    wb.set_workspace([-6.0, -6.0, 6.0, 6.0])  \n",
    "    \n",
    "    robot = moveit_commander.RobotCommander()\n",
    "    scene = moveit_commander.PlanningSceneInterface()\n",
    "    \n",
    "    tf_man = TF_MANAGER()\n",
    "    rgbd = RGBD()\n",
    "    hand_cam = HAND_RGB()\n",
    "    wrist = WRIST_SENSOR()\n",
    "    gripper = GRIPPER()\n",
    "    grasp_base = OMNIBASE()\n",
    "    gaze = GAZE()\n",
    "\n",
    "    clear_octo_client = rospy.ServiceProxy('/clear_octomap', Empty)\n",
    "    calibrate_wrist = rospy.ServiceProxy('/hsrb/wrist_wrench/readjust_offset',Empty)\n",
    "    AR_starter = rospy.ServiceProxy('/marker/start_recognition',Empty)\n",
    "    AR_stopper = rospy.ServiceProxy('/marker/stop_recognition',Empty)\n",
    "    \n",
    "    head.set_planning_time(0.3)\n",
    "    head.set_num_planning_attempts(1)\n",
    "    wb.set_num_planning_attempts(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(msg):\n",
    "    talker = rospy.Publisher('/talk_request', Voice, queue_size=10)\n",
    "    voice = Voice()\n",
    "    voice.language = 1\n",
    "    voice.sentence = msg\n",
    "    talker.publish(voice)\n",
    "    \n",
    "\n",
    "    \n",
    "def correct_points(low_plane=0.0, high_plane=0.2):\n",
    "\n",
    "    #Corrects point clouds \"perspective\" i.e. Reference frame head is changed to reference frame map\n",
    "    data = rospy.wait_for_message('/hsrb/head_rgbd_sensor/depth_registered/rectified_points', PointCloud2)\n",
    "    np_data = ros_numpy.numpify(data)\n",
    "    \n",
    "#   new implementation to use only tf2\n",
    "#     transf = tfbuff.lookup_transform('map', 'head_rgbd_sensor_gazebo_frame', rospy.Time())\n",
    "    \n",
    "#     [trans, rot] = tf2_obj_2_arr(transf)\n",
    "    trans, rot = tf_man.getTF(target_frame= 'head_rgbd_sensor_gazebo_frame')\n",
    "    eu = np.asarray(tf.transformations.euler_from_quaternion(rot))\n",
    "    t = TransformStamped()\n",
    "    rot = tf.transformations.quaternion_from_euler(-eu[1], 0, 0)\n",
    "    t.header.stamp = data.header.stamp\n",
    "    \n",
    "    t.transform.rotation.x = rot[0]\n",
    "    t.transform.rotation.y = rot[1]\n",
    "    t.transform.rotation.z = rot[2]\n",
    "    t.transform.rotation.w = rot[3]\n",
    "\n",
    "    cloud_out = do_transform_cloud(data, t)\n",
    "    np_corrected = ros_numpy.numpify(cloud_out)\n",
    "    corrected = np_corrected.reshape(np_data.shape)\n",
    "\n",
    "    img = np.copy(corrected['y'])\n",
    "\n",
    "    img[np.isnan(img)] = 2\n",
    "    #img3 = np.where((img>low)&(img< 0.99*(trans[2])),img,255)\n",
    "    img3 = np.where((img>0.99*(trans[2])-high_plane)&(img< 0.99*(trans[2])-low_plane),img,255)\n",
    "    return img3\n",
    "\n",
    "def plane_seg_square_imgs(lower=500, higher=50000, reg_ly= 30, reg_hy=600, plt_images=True, low_plane=.0, high_plane=0.2):\n",
    "\n",
    "    #Segment  Plane using corrected point cloud\n",
    "    #Lower, higher = min, max area of the box\n",
    "    #reg_ly= 30,reg_hy=600    Region (low y  region high y ) Only centroids within region are accepted\n",
    "    \n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    img = np.copy(image)\n",
    "    img3 = correct_points(low_plane,high_plane)\n",
    "    \n",
    "#     cv2 on python 3\n",
    "    contours, hierarchy = cv2.findContours(img3.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    points = []\n",
    "    images = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            img = cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "                image_aux = iimmg[boundRect[1]:boundRect[1]+max(boundRect[2],boundRect[3]),boundRect[0]:boundRect[0]+max(boundRect[2],boundRect[3])]\n",
    "                images.append(image_aux)\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}',    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0] + boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1] + boundRect[3]):\n",
    "                        aux = (np.asarray((points_data['x'][ix,jy], points_data['y'][ix,jy], points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "#                 print (cent)\n",
    "                points.append(xyz)\n",
    "#             else:\n",
    "#                 print ('cent out of region... rejected')\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "           \n",
    "            sub_plt += 1\n",
    "            ax = plt.subplot(5, 5, sub_plt)\n",
    "          \n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents = np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def seg_square_imgs(lower=2000, higher=50000, reg_ly=0, reg_hy=1000, reg_lx=0, reg_hx=1000, plt_images=True): \n",
    "\n",
    "#     Using kmeans for image segmentation find\n",
    "#     Lower, higher = min, max area of the box\n",
    "#     reg_ly= 30,reg_hy=600,reg_lx=0,reg_hx=1000, \n",
    "#     Region (low  x,y  region high x,y ) Only centroids within region are accepted\n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    values = image.reshape((-1,3))\n",
    "    values = np.float32(values)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k = 6\n",
    "    _ , labels , cc = cv2.kmeans(values, k, None, criteria, 30, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc = np.uint8(cc)\n",
    "    segmented_image = cc[labels.flatten()]\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    im4 = cv2.erode(th3, kernel, iterations = 4)\n",
    "    plane_mask = points_data['z']\n",
    "    cv2_img = plane_mask.astype('uint8')\n",
    "    img = im4\n",
    "    contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    points = []\n",
    "    images = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux = iimmg[boundRect[1]:boundRect[1] + max(boundRect[3],boundRect[2]),boundRect[0]:boundRect[0]+max(boundRect[3],boundRect[2])]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            #img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+max(boundRect[2],boundRect[3]), boundRect[1]+max(boundRect[2],boundRect[3])), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy and  cX > reg_lx and cX < reg_hx   ):\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}', (cX - 25, cY - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                #print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                #print ('cent out of region... rejected')\n",
    "                images.pop()\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "    cents=np.asarray(cents)\n",
    "    #images.append(img)\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def static_tf_publish(cents):\n",
    "#     Publish tfs of the centroids obtained w.r.t. head sensor frame and references them to map (static)\n",
    "    transf = tfbuff.lookup_transform('map', 'base_link', rospy.Time(0))\n",
    "    [trans, rot] = tf2_obj_2_arr(transf)\n",
    "#     closest_centroid_index=  np.argmin(np.linalg.norm(trans-cents, axis=1))##CLOSEST CENTROID\n",
    "    closest_centroid_index = 0\n",
    "    min_D_to_base = 10\n",
    "    for  i, cent  in enumerate(cents):\n",
    "        x, y, z = cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan')\n",
    "        else:\n",
    "            t = TransformStamped()\n",
    "            t.header.stamp = rospy.Time.now()\n",
    "            t.header.frame_id = \"head_rgbd_sensor_link\"\n",
    "            t.child_frame_id = f'Object{i}'\n",
    "            t.transform.translation.x = x\n",
    "            t.transform.translation.y = y\n",
    "            t.transform.translation.z = z\n",
    "            t.transform.rotation.x = rot[0]\n",
    "            t.transform.rotation.y = rot[1]\n",
    "            t.transform.rotation.z = rot[2]\n",
    "            t.transform.rotation.w = rot[3]\n",
    "            broad.sendTransform(t)\n",
    "#             broad.sendTransform((x,y,z), rot, rospy.Time.now(), 'Object'+str(i), \"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(0.5)\n",
    "            transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "            [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "            D_to_base = np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2])\n",
    "            if D_to_base <= min_D_to_base:\n",
    "                min_D_to_base = D_to_base\n",
    "                closest_centroid_index = i\n",
    "                closest_centroid_height = xyz_map[2]\n",
    "            print ('Distance: base to obj - ', i, np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2]))\n",
    "    i = closest_centroid_index\n",
    "    transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "    [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "    print('Height closest centroid map', xyz_map[2])\n",
    "    map_euler = tf.transformations.euler_from_quaternion(cent_quat)\n",
    "    rospy.sleep(.5)\n",
    "#     FIXING TF TO MAP ( ODOM REALLY)    \n",
    "    static_ts = TransformStamped()\n",
    "    static_ts.header.stamp = rospy.Time.now()\n",
    "    static_ts.header.frame_id = \"map\"\n",
    "    static_ts.child_frame_id = 'cassette'\n",
    "    static_ts.transform.translation.x = float(xyz_map[0])\n",
    "    static_ts.transform.translation.y = float(xyz_map[1])\n",
    "    static_ts.transform.translation.z = float(xyz_map[2])\n",
    "#     quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "    static_ts.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "    static_ts.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "    static_ts.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "    static_ts.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "    print ('xyz_map', xyz_map)\n",
    "    tf_static_broad.sendTransform(static_ts)\n",
    "    return closest_centroid_height, closest_centroid_index\n",
    "def publish_point_tf(x,y,z,pointName, ref=\"map\"):\n",
    "    static_ts = TransformStamped()\n",
    "    static_ts.header.stamp = rospy.Time.now()\n",
    "    static_ts.header.frame_id = ref\n",
    "    static_ts.child_frame_id = f'Point {pointName}'\n",
    "    static_ts.transform.translation.x = x\n",
    "    static_ts.transform.translation.y = y\n",
    "    static_ts.transform.translation.z = z\n",
    "    static_ts.transform.rotation.x = 0\n",
    "    static_ts.transform.rotation.y = 0\n",
    "    static_ts.transform.rotation.z = 0\n",
    "    static_ts.transform.rotation.w = 1\n",
    "    tf_static_broad.sendTransform(static_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da811f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape detection\n",
    "import matplotlib.pyplot as plt\n",
    "img = rgbd.get_image()\n",
    "\n",
    "plt.imshow(img)\n",
    "# img = np\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)[1]\n",
    "\n",
    "ROI_number = 0\n",
    "cnts = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "for cnt in cnts:\n",
    "    approx = cv.approxPolyDP(cnt,0.01*cv.arcLength(cnt,True),True)\n",
    "    print(len(approx))\n",
    "    if len(approx)==5:\n",
    "        print(\"Blue = pentagon\")\n",
    "        cv.drawContours(img,[cnt],0,255,-1)\n",
    "    elif len(approx)==3:\n",
    "        print(\"Green = triangle\")\n",
    "        cv.drawContours(img,[cnt],0,(0,255,0),-1)\n",
    "    elif len(approx)==4:\n",
    "        print(\"Red = square\")\n",
    "        cv.drawContours(img,[cnt],0,(0,0,255),-1)\n",
    "    elif len(approx) == 6:\n",
    "        print(\"Cyan = Hexa\")\n",
    "        cv.drawContours(img,[cnt],0,(255,255,0),-1)\n",
    "    elif len(approx) == 8:\n",
    "        print(\"White = Octa\")\n",
    "        cv.drawContours(img,[cnt],0,(255,255,255),-1)\n",
    "    elif len(approx) > 12:\n",
    "        print(\"Yellow = circle\")\n",
    "        cv.drawContours(img,[cnt],0,(0,255,255),-1)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('Binary',thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72289e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd.color_segmentator(color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arm.set_named_target('go')\n",
    "# arm.go()\n",
    "# tiny_move_base(x=0.5,std_time=0.3)\n",
    "hcp= [0,-0.5]\n",
    "head.set_joint_value_target(hcp)\n",
    "head.go()\n",
    "color_segmentator(cam = 'head', color = 'blue',plot=True)\n",
    "goalPos = [238.7, 267.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497bada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d336102",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03776c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "publish_point_tf(1,-2,2,'Object', ref='map')\n",
    "# grasp_base.tiny_move(velT=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdbaac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place_height=arm.get_current_joint_values()\n",
    "print(place_height)\n",
    "altura_optima = 0.1199\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bc5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traf = tfbuff.lookup_transform('arm_flex_link', 'Point Object', rospy.Time(0))\n",
    "trans, rot = tf2_obj_2_arr(traf)\n",
    "# print(trans,rot)\n",
    "phi = np.arctan2(trans[1],trans[0])\n",
    "base_point = np.array((trans[0], trans[1]))\n",
    "distXY = np.linalg.norm(base_point)\n",
    "print(phi, distXY)\n",
    "succ = False\n",
    "THRESHOLD = 0.02\n",
    "while not succ:\n",
    "    traf = tfbuff.lookup_transform('arm_flex_link', 'Point Object', rospy.Time(0))\n",
    "    trans, rot = tf2_obj_2_arr(traf)\n",
    "    # print(trans,rot)\n",
    "    phi = np.arctan2(trans[1],trans[0])\n",
    "    print(phi)\n",
    "    if abs(phi)< THRESHOLD:\n",
    "        succ =True\n",
    "    else:\n",
    "        grasp_base.tiny_move(velT = 0.5*phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37eb419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traf = tfbuff.lookup_transform('base_link', 'Point Object', rospy.Time(0))\n",
    "trans, rot = tf2_obj_2_arr(traf)\n",
    "# print(trans,rot)\n",
    "phi = np.arctan2(trans[1],trans[0])\n",
    "dist = np.sqrt(np.square(trans[0])+np.square(trans[1]))\n",
    "print(phi, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e3c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grasp_base.tiny_move(velT=0.5)\n",
    "acp= arm.get_current_joint_values()\n",
    "acp[1] =-0.5\n",
    "arm.set_joint_value_target(acp)\n",
    "# arm.set_named_target('neutral')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp= [0,0.0]\n",
    "head.set_joint_value_target(hcp)\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faccdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb5c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculo de la lambda necesaria para el efector final a partir del arm_roll_link\n",
    "arm_link = 'arm_flex_link'\n",
    "# arm_link = 'arm_roll_link'\n",
    "traf_arl = tfbuff.lookup_transform(\"base_link\",arm_link, rospy.Time(0)) #arm_roll_link\n",
    "traf_point = tfbuff.lookup_transform(\"base_link\",\"Point Object\", rospy.Time(0))\n",
    "A, _ = tf2_obj_2_arr(traf_arl) #Vector de posicion ARL\n",
    "B, _ = tf2_obj_2_arr(traf_point) #Vector de posicion de objeto\n",
    "# print(trans1,trans2)\n",
    "A=np.array(A)\n",
    "B=np.array(B)\n",
    "V = np.add(-1*A,B) #Vector de direccion AB\n",
    "# V=V*(1/abs(V))\n",
    "# print(V)\n",
    "traf_wrist = tfbuff.lookup_transform(arm_link,\"hand_palm_link\", rospy.Time(0))\n",
    "trans3, _ = tf2_obj_2_arr(traf_wrist)\n",
    "distance=np.linalg.norm(trans3)\n",
    "\n",
    "V2= [n**2 for n in V]\n",
    "V2=np.sum(V2)\n",
    "\n",
    "l1 = distance/np.sqrt(V2)\n",
    "print(l1)\n",
    "\n",
    "# print(vector_dir)\n",
    "posicion = np.add(A,V*1*l1)\n",
    "\n",
    "print(posicion)\n",
    "publish_point_tf(posicion[0],posicion[1],posicion[2], 'posicion',ref='base_link')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_at(target=\"Point Object\",alpha =0.0):\n",
    "#     arm.set_named_target('neutral')\n",
    "#     arm.go()\n",
    "    arm_f = 'arm_flex_link'\n",
    "    arm_r= 'arm_roll_link'\n",
    "    afl = tfbuff.lookup_transform(arm_f,\"Point Object\", rospy.Time(0)) #arm_roll_link\n",
    "    arl = tfbuff.lookup_transform(arm_r,\"Point Object\", rospy.Time(0))\n",
    "    al = tfbuff.lookup_transform(arm_f,arm_r, rospy.Time(0))\n",
    "    afl, _ = tf2_obj_2_arr(afl) #Vector de posicion Arm Flex Link (codo)\n",
    "    arl, _ = tf2_obj_2_arr(arl) #Vector de posicion Arm Roll Link (muñeca)\n",
    "    al,_ = tf2_obj_2_arr(al) #Medida del brazo\n",
    "    \n",
    "    FR=al[2]\n",
    "    RO= np.sqrt(arl[0]**2+arl[2]**2)\n",
    "##geometria con 1 angulo\n",
    "    z = afl[2]\n",
    "    p = afl[0]\n",
    "    xi = np.arctan2(p,z)\n",
    "#     print(xi)\n",
    "    beta = np.arcsin((-FR*np.sin(alpha+xi))/RO)+alpha+xi\n",
    "    return alpha,beta   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17815c9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_pose=arm.get_current_joint_values()\n",
    "# point_pose[1]=-alpha\n",
    "# point_pose[3]=-np.pi+beta\n",
    "# arm.set_joint_value_target(point_pose)\n",
    "# arm.set_named_target('neutral')\n",
    "arm.set_named_target('neutral')\n",
    "arm.go()\n",
    "a = 0.2\n",
    "while(a < 2.61):\n",
    "    alpha,beta =point_at(alpha=a)\n",
    "    print(alpha,beta)\n",
    "    point_pose[1]=-alpha\n",
    "    point_pose[3]=-beta\n",
    "    try:\n",
    "        arm.set_joint_value_target(point_pose)\n",
    "        succ=arm.go()\n",
    "        if(succ):\n",
    "            a=5\n",
    "    except:\n",
    "        a+=0.05\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286289c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm.set_named_target('neutral')\n",
    "arm.go()\n",
    "\n",
    "# arm.set_pose_reference_frame('base_link')\n",
    "# arm.get_pose_reference_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bee55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gaze = GAZE()\n",
    "hcp = gaze.relative(2,1,0)\n",
    "head.set_joint_value_target(hcp)\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e0823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm.set_named_target('neutral')\n",
    "arm.go()\n",
    "# traf1 = tfbuff.lookup_transform('base_link','hand_palm_link', rospy.Time(0))\n",
    "# _,rot = tf2_obj_2_arr(traf1)\n",
    "# e = tf.transformations.euler_from_quaternion(rot)\n",
    "# print(e)\n",
    "# rot=[0,0,0]\n",
    "# rot[0] = e[0] + 3.14\n",
    "# rot[1] = e[1] + 1.57\n",
    "# rot[2] = e[2]\n",
    "print(e)\n",
    "# ori = tf.transformations.quaternion_from_euler(rot[0],rot[1], rot[2])\n",
    "# arm.set_rpy_target([3.14,0,0])\n",
    "# arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde586e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grasp_base.tiny_move(velX=0.2, MAX_VEL=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2efad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "succ = False\n",
    "THRESHOLD = 0.05\n",
    "phi = np.arctan(trans[1]/trans[0])\n",
    "while not succ:\n",
    "    traf = tfbuff.lookup_transform(\"arm_flex_link\",\"cassette\", rospy.Time(0))\n",
    "    # print(traf)\n",
    "    trans, rot = tf2_obj_2_arr(traf)\n",
    "    rot = tf.transformations.euler_from_quaternion(rot)\n",
    "    alpha = rot[2]\n",
    "    xi = alpha - phi\n",
    "    grasp_base.tiny_move(velT=xi)\n",
    "    print(xi)\n",
    "    if abs(xi) < THRESHOLD:\n",
    "        succ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_point_tf(1,0,0,'Brazo1',ref='head_rgbd_sensor_gazebo_frame')\n",
    "traf = tfbuff.lookup_transform('map','Point Brazo1', rospy.Time(0))\n",
    "trans,_ = tf2_obj_2_arr(traf)\n",
    "publish_point_tf(trans[0],trans[1],trans[2],'Brazo2',ref='map')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.steady()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b74c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traf = tfbuff.lookup_transform('base_link','ar_marker/201',rospy.Time(0))\n",
    "tf2_obj_2_arr(traf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze = GAZE()\n",
    "# rospy.sleep(0.3)\n",
    "hcp = gaze.relative(1,0,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "head.set_joint_value_target(hcp)\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_from_above_joints = [0.5 - 0.102,-1.3376,0,-1.8275,0.0,0.0]\n",
    "arm.set_joint_value_target(grasp_from_above_joints)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "head.set_joint_value_target(hcp)\n",
    "plan1=head.plan()\n",
    "print(plan1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eab138",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.pub_tf(pos=[0,0,1],point_name=\"Prueba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e565b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.pub_static_tf(pos=[1,1,0], point_name=\"Prueba2\", ref=\"base_link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.getTF(target_frame=\"Prueba2\", ref_frame=\"hand_palm_link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9f1e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_man.change_ref_frame_tf(point_name=\"Prueba2\", new_frame=\"hand_palm_link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "succ = False\n",
    "pos_init, _ = tf_man.getTF(target_frame='hand_l_finger_tip_frame', ref_frame='base_link')\n",
    "print(trans)\n",
    "while not succ:\n",
    "    \n",
    "    print(wrist.get_force())\n",
    "    rospy.sleep(1)\n",
    "    succ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6320e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.shift_pose_target(1,0.02)\n",
    "plan=arm.plan()\n",
    "print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = arm.get_current_pose()\n",
    "print(pose)\n",
    "pose.pose.position.x -= 0.2\n",
    "arm.set_pose_target(pose)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.set_pose_reference_frame('base_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.get_current_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e58c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_man.getTF(target_frame='arm_roll_link', ref_frame='odom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.shift_pose_target(1,0.02)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0540e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.steady()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.set_named_target('go')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_base.tiny_move(velT=-1, MAX_VEL=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aec05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, rot=tf_man.getTF(target_frame='cassette', ref_frame='odom')\n",
    "trans[2] += 0.2\n",
    "whole_body.set_position_target(trans)\n",
    "plan1= whole_body.plan()\n",
    "print(plan1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAND_RGB():\n",
    "    def __init__(self):\n",
    "        self.cam_sub = rospy.Subscriber(\n",
    "            '/hsrb/hand_camera/image_raw',\n",
    "            ImageMsg, self._callback)\n",
    "        self._points_data = None\n",
    "        self._image_data = None\n",
    "        \n",
    "    def _callback(self, msg):\n",
    "        self._image_data = ros_numpy.numpify(msg)\n",
    "        \n",
    "    def get_image(self):\n",
    "        image = self._image_data\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    \n",
    "#Color segmentator\n",
    "    def color_segmentator(self, color = \"orange\"):\n",
    "        image = self.get_image()\n",
    "        if(color == \"blue\"):\n",
    "            lower_threshold = (100,120,100)\n",
    "            upper_threshold = (150,220,240)\n",
    "        else:\n",
    "            lower_threshold = (105,130,100)\n",
    "            upper_threshold = (115,225,255)\n",
    "        img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        mask = cv2.inRange(img_hsv, lower_threshold, upper_threshold)\n",
    "        res = cv2.bitwise_and(img_hsv, img_hsv, mask=mask)\n",
    "        pos = []\n",
    "        pixels = cv2.findNonZero(mask)\n",
    "        pixels = list(cv2.mean(pixels))\n",
    "        pos.append(pixels[:2])\n",
    "        return pos, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = HAND_RGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c976c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pos, img = hand.color_segmentator()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23feab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "        succ = False\n",
    "        X_THRESHOLD = 20\n",
    "        Y_THRESHOLD = 10\n",
    "        goalPos = [258.61,261.75]\n",
    "        while not succ:\n",
    "            [currentPos] = hand_cam.color_segmentator(color = 'orange')\n",
    "#     print(currentPos)\n",
    "            ex = -(goalPos[0]-currentPos[0]) \n",
    "            ey = (goalPos[1]-currentPos[1])\n",
    "            print(ex, ey)\n",
    "            if abs(ex) > X_THRESHOLD:\n",
    "                grasp_base.tiny_move(velX = 0.001*ex, std_time=0.05, MAX_VEL=0.02)#, y = -traf.y + Y_OFFSET)\n",
    "                rospy.sleep(0.5)\n",
    "            if abs(ey) > Y_THRESHOLD:\n",
    "                grasp_base.tiny_move(velY = 0.001*ey, std_time=0.05, MAX_VEL=0.02)\n",
    "                rospy.sleep(0.5)\n",
    "            if (abs(ex) <= X_THRESHOLD and abs(ey) <= Y_THRESHOLD):\n",
    "#                 talk(\"done, now i will take it\")\n",
    "                succ = True\n",
    "#             rospy.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rot = tf_man.getTF(target_frame='base_link', ref_frame='map')\n",
    "theta = rot[2]\n",
    "print(theta)\n",
    "vel = 0.3\n",
    "succ = False\n",
    "diff=0.0\n",
    "while abs(diff) < 1:\n",
    "    _, rot = tf_man.getTF(target_frame='base_link')\n",
    "    alpha = rot[2]\n",
    "    diff = theta - alpha\n",
    "    print(diff)\n",
    "    grasp_base.tiny_move(velT=-vel, std_time=0.3)\n",
    "while abs(diff) < 1 :\n",
    "    _, rot = tf_man.getTF(target_frame='base_link')\n",
    "    alpha = rot[2]\n",
    "    diff = theta - alpha\n",
    "    print(diff)\n",
    "    grasp_base.tiny_move(velT=-1*vel, std_time=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.get_current_joint_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.steady()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419447fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents, points, images = plane_seg_square_imgs(low_plane=0.8, high_plane=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents, point, images = seg_square_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.pub_tf(pos = cents[0], point_name='prueba', ref='map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725b3f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AR_starter.call()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954b2187",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, rot = tf_man.getTF(target_frame='ar_marker/7')\n",
    "tf_man.pub_static_tf(point_name='player', pos=pos, rot=rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87d4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy = tf.transformations.euler_from_quaternion(rot)\n",
    "# whole_body.set_rpy_target(rpy)\n",
    "# whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f909aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, rot = tf_man.getTF(target_frame='player', ref_frame='hand_palm_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5789752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11490643498530506, -0.37741284743128045, 0.09297953633480707] [-0.5099126787118813, 0.49551424992893667, -0.4910807066860005, -0.5032836453999023]\n"
     ]
    }
   ],
   "source": [
    "print(pos, rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bc7541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9660019978646937, -1.5419853780206814, -0.39300995273845923)\n"
     ]
    }
   ],
   "source": [
    "rpy = tf.transformations.euler_from_quaternion(rot)\n",
    "print(rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af85203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acp = arm.get_current_joint_values()\n",
    "# print(acp)\n",
    "arm.set_named_target('neutral')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd23947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acp[4] = -1.5707\n",
    "arm.set_joint_value_target(acp)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b7baae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1668796706.560043]: Distance to goal: -0.045, 0.010\n",
      "[INFO] [1668796706.851597]: Distance to goal: -0.045, 0.010\n",
      "[INFO] [1668796707.197932]: Distance to goal: -0.045, 0.009\n",
      "[INFO] [1668796707.501867]: Distance to goal: -0.041, 0.009\n",
      "[INFO] [1668796707.848251]: Distance to goal: -0.041, 0.005\n",
      "[INFO] [1668796708.222430]: Distance to goal: -0.037, 0.003\n",
      "[INFO] [1668796708.501659]: Distance to goal: -0.035, 0.003\n",
      "[INFO] [1668796708.873553]: Distance to goal: -0.032, 0.001\n",
      "[INFO] [1668796709.234168]: Distance to goal: -0.030, 0.001\n",
      "[INFO] [1668796709.514261]: Distance to goal: -0.029, 0.002\n",
      "[INFO] [1668796709.821199]: Distance to goal: -0.027, -0.000\n",
      "[INFO] [1668796710.171627]: Distance to goal: -0.025, 0.001\n",
      "[INFO] [1668796710.509876]: Distance to goal: -0.024, 0.001\n",
      "[INFO] [1668796710.811416]: Distance to goal: -0.022, 0.001\n",
      "[INFO] [1668796711.115934]: Distance to goal: -0.023, 0.000\n",
      "[INFO] [1668796711.417858]: Distance to goal: -0.019, 0.001\n",
      "[INFO] [1668796711.756548]: Distance to goal: -0.020, 0.002\n",
      "[INFO] [1668796712.017788]: Distance to goal: -0.018, 0.001\n",
      "[INFO] [1668796712.357501]: Distance to goal: -0.017, 0.002\n",
      "[INFO] [1668796712.611351]: Distance to goal: -0.018, 0.002\n",
      "[INFO] [1668796712.903511]: Distance to goal: -0.014, 0.001\n",
      "[INFO] [1668796713.276034]: Distance to goal: -0.013, 0.000\n",
      "[INFO] [1668796713.616770]: Distance to goal: -0.012, -0.000\n",
      "[INFO] [1668796713.910166]: Distance to goal: -0.013, 0.001\n",
      "[INFO] [1668796714.163424]: Distance to goal: -0.013, 0.001\n",
      "[INFO] [1668796714.455338]: Distance to goal: -0.013, 0.001\n",
      "[INFO] [1668796714.811483]: Distance to goal: -0.010, 0.002\n",
      "[INFO] [1668796715.125462]: Distance to goal: -0.010, 0.001\n",
      "[INFO] [1668796715.357567]: Distance to goal: -0.010, 0.000\n",
      "[INFO] [1668796715.695828]: Distance to goal: -0.010, 0.002\n",
      "[INFO] [1668796716.140223]: Distance to goal: -0.010, 0.003\n",
      "[INFO] [1668796716.421605]: Distance to goal: -0.008, 0.001\n",
      "[INFO] [1668796716.661366]: Distance to goal: -0.007, 0.002\n",
      "[INFO] [1668796716.940330]: Distance to goal: -0.007, 0.001\n",
      "[INFO] [1668796717.184529]: Distance to goal: -0.006, -0.000\n",
      "[INFO] [1668796717.498059]: Distance to goal: -0.007, 0.001\n",
      "[INFO] [1668796717.836786]: Distance to goal: -0.008, 0.001\n",
      "[INFO] [1668796718.186064]: Distance to goal: -0.006, 0.001\n",
      "[INFO] [1668796718.488156]: Distance to goal: -0.004, -0.001\n"
     ]
    }
   ],
   "source": [
    "        #Align with player\n",
    "        succ = False\n",
    "        THRESHOLD = 0.005\n",
    "        while not succ:\n",
    "            trans,_ = tf_man.getTF(target_frame='player', ref_frame='hand_palm_link')\n",
    "            if type(trans) is not bool:\n",
    "                eY, _, eX = trans\n",
    "                eY -= 0.11\n",
    "                eX -= 0.20\n",
    "                rospy.loginfo(\"Distance to goal: {:.3f}, {:.3f}\".format(eX, eY))\n",
    "                if abs(eY) < THRESHOLD:\n",
    "                    eY = 0\n",
    "                if abs(eX) < THRESHOLD:\n",
    "                    eX = 0\n",
    "                succ =  eX == 0 and eY == 0\n",
    "#                 rospy.sleep(1.0)\n",
    "                grasp_base.tiny_move(velX=0.15*eX, velY=0.4*eY, std_time=0.2, MAX_VEL=0.3) #Pending test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0dd9c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos, rot = tf_man.getTF(target_frame='hand_palm_link', ref_frame='odom')\n",
    "trans,_ = tf_man.getTF(target_frame='player', ref_frame='hand_palm_link')\n",
    "# print(trans)\n",
    "# trans[2]-=0.30\n",
    "\n",
    "pos[2]+=(trans[1]+0.014)\n",
    "\n",
    "# print(pos)\n",
    "pose_goal = set_pose_goal(pos=pos, rot = rot)\n",
    "arm.set_start_state_to_current_state()\n",
    "arm.set_pose_target(pose_goal)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9855da2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf_man.pub_static_tf(point_name='goal_pose', pos=[0,0,0.04], ref='hand_palm_link')\n",
    "\n",
    "pos, rot = tf_man.getTF(target_frame='goal_pose', ref_frame='odom')\n",
    "\n",
    "pose_goal = set_pose_goal(pos=pos, rot = rot)\n",
    "arm.set_start_state_to_current_state()\n",
    "arm.set_pose_target(pose_goal)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f9789f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_wrist = rospy.ServiceProxy('/hsrb/wrist_wrench/readjust_offset',Empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a13b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrate_wrist.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ee80fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrist.get_force()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f7bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.09093526832003\n"
     ]
    }
   ],
   "source": [
    "#Primera aproximacion\n",
    "succ = False\n",
    "while not succ:\n",
    "    force = wrist.get_force()\n",
    "    f = np.array(force)\n",
    "    mag_force = np.linalg.norm(f)\n",
    "    if mag_force < 9:\n",
    "        grasp_base.tiny_move(velX=0.005, std_time=0.05)\n",
    "    else:\n",
    "        vel = -0.01\n",
    "        grasp_base.tiny_move(velX=0.0, std_time=0.05)\n",
    "        if force[0] > 0.0:\n",
    "                vel = -vel\n",
    "        grasp_base.tiny_move(velY=-vel, std_time=0.05)\n",
    "        succ = True\n",
    "print(force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f91eb7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.117709023208201\n"
     ]
    }
   ],
   "source": [
    "#Segunda aproximacion\n",
    "succ = False\n",
    "while not succ:\n",
    "    force = wrist.get_force()\n",
    "    force = np.array(force)\n",
    "    force = np.linalg.norm(force)\n",
    "    if force < 9:\n",
    "        grasp_base.tiny_move(velX=0.005, std_time=0.05)\n",
    "    else:\n",
    "        grasp_base.tiny_move(velX=-0.01, std_time=0.05)\n",
    "#         grasp_base.tiny_move(velY=-0.01, std_time=0.05)\n",
    "        \n",
    "#         grasp_base.tiny_move(velX=-0.1, std_time=0.05)\n",
    "        succ = True\n",
    "print(force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "329b8ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.008783342401012422, 0.26648647343603976, 2.229921655543579]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " wrist.get_force()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622c497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.13613257005361365, 0.02660417992296704, 0.019877414099348734],\n",
       " [-0.006905209244227028,\n",
       "  -0.7371062425869601,\n",
       "  -0.6751923371320537,\n",
       "  -0.02723991745182947]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_man.getTF(target_frame='player', ref_frame='hand_r_finger_tip_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8640b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
