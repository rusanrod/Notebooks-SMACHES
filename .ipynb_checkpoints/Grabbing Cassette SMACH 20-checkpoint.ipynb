{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a863b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takeshi STATE MACHINE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m[ERROR] [1666028419.200004617]: [registerPublisher] Failed to contact master at [hsrb.local:11311].  Retrying...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import smach\n",
    "import rospy\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from std_srvs.srv import Empty\n",
    "from tmc_msgs.msg import Voice\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "import tf2_ros as tf2\n",
    "from tf2_sensor_msgs.tf2_sensor_msgs import do_transform_cloud\n",
    "from utils_takeshi import *\n",
    "from grasp_utils import *\n",
    "\n",
    "def talk(msg):\n",
    "    talker = rospy.Publisher('/talk_request', Voice, queue_size=10)\n",
    "    voice = Voice()\n",
    "    voice.language = 1\n",
    "    voice.sentence = msg\n",
    "    talker.publish(voice)\n",
    "    \n",
    "def correct_points(low_plane=0.0, high_plane=0.2):\n",
    "\n",
    "    #Corrects point clouds \"perspective\" i.e. Reference frame head is changed to reference frame map\n",
    "    data = rospy.wait_for_message('/hsrb/head_rgbd_sensor/depth_registered/rectified_points', PointCloud2)\n",
    "    np_data = ros_numpy.numpify(data)\n",
    "    \n",
    "#   new implementation to use only tf2\n",
    "    transf = tfbuff.lookup_transform('map', 'head_rgbd_sensor_gazebo_frame', rospy.Time())\n",
    "    [trans, rot] = tf2_obj_2_arr(transf)\n",
    "    \n",
    "    eu = np.asarray(tf.transformations.euler_from_quaternion(rot))\n",
    "    t = TransformStamped()\n",
    "    rot = tf.transformations.quaternion_from_euler(-eu[1], 0, 0)\n",
    "    t.header.stamp = data.header.stamp\n",
    "    \n",
    "    t.transform.rotation.x = rot[0]\n",
    "    t.transform.rotation.y = rot[1]\n",
    "    t.transform.rotation.z = rot[2]\n",
    "    t.transform.rotation.w = rot[3]\n",
    "\n",
    "    cloud_out = do_transform_cloud(data, t)\n",
    "    np_corrected = ros_numpy.numpify(cloud_out)\n",
    "    corrected = np_corrected.reshape(np_data.shape)\n",
    "\n",
    "    img = np.copy(corrected['y'])\n",
    "\n",
    "    img[np.isnan(img)] = 2\n",
    "    #img3 = np.where((img>low)&(img< 0.99*(trans[2])),img,255)\n",
    "    img3 = np.where((img>0.99*(trans[2])-high_plane)&(img< 0.99*(trans[2])-low_plane),img,255)\n",
    "    return img3\n",
    "\n",
    "def plane_seg_square_imgs(lower=500, higher=50000, reg_ly= 30, reg_hy=600, plt_images=True, low_plane=.0, high_plane=0.2):\n",
    "\n",
    "    #Segment  Plane using corrected point cloud\n",
    "    #Lower, higher = min, max area of the box\n",
    "    #reg_ly= 30,reg_hy=600    Region (low y  region high y ) Only centroids within region are accepted\n",
    "    \n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    img = np.copy(image)\n",
    "    img3 = correct_points(low_plane,high_plane)\n",
    "    \n",
    "#     cv2 on python 3\n",
    "    contours, hierarchy = cv2.findContours(img3.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    points = []\n",
    "    images = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            img = cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "                image_aux = iimmg[boundRect[1]:boundRect[1]+max(boundRect[2],boundRect[3]),boundRect[0]:boundRect[0]+max(boundRect[2],boundRect[3])]\n",
    "                images.append(image_aux)\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}',    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0] + boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1] + boundRect[3]):\n",
    "                        aux = (np.asarray((points_data['x'][ix,jy], points_data['y'][ix,jy], points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "#                 print (cent)\n",
    "                points.append(xyz)\n",
    "#             else:\n",
    "#                 print ('cent out of region... rejected')\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "           \n",
    "            sub_plt += 1\n",
    "            ax = plt.subplot(5, 5, sub_plt)\n",
    "          \n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents = np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def seg_square_imgs(lower=2000, higher=50000, reg_ly=0, reg_hy=1000, reg_lx=0, reg_hx=1000, plt_images=True): \n",
    "\n",
    "#     Using kmeans for image segmentation find\n",
    "#     Lower, higher = min, max area of the box\n",
    "#     reg_ly= 30,reg_hy=600,reg_lx=0,reg_hx=1000, \n",
    "#     Region (low  x,y  region high x,y ) Only centroids within region are accepted\n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    values = image.reshape((-1,3))\n",
    "    values = np.float32(values)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k = 6\n",
    "    _ , labels , cc = cv2.kmeans(values, k, None, criteria, 30, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc = np.uint8(cc)\n",
    "    segmented_image = cc[labels.flatten()]\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    im4 = cv2.erode(th3, kernel, iterations = 4)\n",
    "    plane_mask = points_data['z']\n",
    "    cv2_img = plane_mask.astype('uint8')\n",
    "    img = im4\n",
    "    contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    points = []\n",
    "    images = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux = iimmg[boundRect[1]:boundRect[1] + max(boundRect[3],boundRect[2]),boundRect[0]:boundRect[0]+max(boundRect[3],boundRect[2])]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            #img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+max(boundRect[2],boundRect[3]), boundRect[1]+max(boundRect[2],boundRect[3])), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy and  cX > reg_lx and cX < reg_hx   ):\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}', (cX - 25, cY - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                #print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                #print ('cent out of region... rejected')\n",
    "                images.pop()\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "    cents=np.asarray(cents)\n",
    "    #images.append(img)\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def static_tf_publish(cents):\n",
    "#     Publish tfs of the centroids obtained w.r.t. head sensor frame and references them to map (static)\n",
    "    transf = tfbuff.lookup_transform('map', 'base_link', rospy.Time(0))\n",
    "    [trans, rot] = tf2_obj_2_arr(transf)\n",
    "#     closest_centroid_index=  np.argmin(np.linalg.norm(trans-cents, axis=1))##CLOSEST CENTROID\n",
    "    closest_centroid_index = 0\n",
    "    min_D_to_base = 10\n",
    "    for  i, cent  in enumerate(cents):\n",
    "        x, y, z = cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan')\n",
    "        else:\n",
    "            t = geometry_msgs.msg.TransformStamped()\n",
    "            t.header.stamp = rospy.Time.now()\n",
    "            t.header.frame_id = \"head_rgbd_sensor_link\"\n",
    "            t.child_frame_id = f'Object{i}'\n",
    "            t.transform.translation.x = x\n",
    "            t.transform.translation.y = y\n",
    "            t.transform.translation.z = z\n",
    "            t.transform.rotation.x = rot[0]\n",
    "            t.transform.rotation.y = rot[1]\n",
    "            t.transform.rotation.z = rot[2]\n",
    "            t.transform.rotation.w = rot[3]\n",
    "            broad.sendTransform(t)\n",
    "#             broad.sendTransform((x,y,z), rot, rospy.Time.now(), 'Object'+str(i), \"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(0.5)\n",
    "            transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "            [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "            D_to_base = np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2])\n",
    "            if D_to_base <= min_D_to_base:\n",
    "                min_D_to_base = D_to_base\n",
    "                closest_centroid_index = i\n",
    "                closest_centroid_height = xyz_map[2]\n",
    "            print ('Distance: base to obj - ', i, np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2]))\n",
    "    i = closest_centroid_index\n",
    "    transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "    [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "    print('Height closest centroid map', xyz_map[2])\n",
    "    map_euler = tf.transformations.euler_from_quaternion(cent_quat)\n",
    "    rospy.sleep(.5)\n",
    "#     FIXING TF TO MAP ( ODOM REALLY)    \n",
    "    static_ts = TransformStamped()\n",
    "    static_ts.header.stamp = rospy.Time.now()\n",
    "    static_ts.header.frame_id = \"map\"\n",
    "    static_ts.child_frame_id = 'cassette'\n",
    "    static_ts.transform.translation.x = float(xyz_map[0])\n",
    "    static_ts.transform.translation.y = float(xyz_map[1])\n",
    "    static_ts.transform.translation.z = float(xyz_map[2])\n",
    "#     quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "    static_ts.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "    static_ts.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "    static_ts.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "    static_ts.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "    print ('xyz_map', xyz_map)\n",
    "    tf_static_broad.sendTransform(static_ts)\n",
    "    return closest_centroid_height, closest_centroid_index\n",
    "\n",
    "##################################\n",
    "\n",
    "            \n",
    "            ########## Functions for takeshi states ##########\n",
    "class Proto_state(smach.State):###example of a state definition.\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : PROTO_STATE')\n",
    "\n",
    "        if self.tries==3:\n",
    "            self.tries=0 \n",
    "            return'tries'\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        global trans_hand\n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            self.tries=0 \n",
    "            return'tries'\n",
    "   \n",
    "        \n",
    "\n",
    "    ##### Define state INITIAL #####\n",
    "#Estado inicial de takeshi, neutral\n",
    "class Initial(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        \n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "# State initial\n",
    "        try:\n",
    "            clear_octo_client()\n",
    "        except:\n",
    "            print('cant clear octomap')\n",
    "        AR_stopper.call()\n",
    "        #Takeshi neutral\n",
    "        arm.set_named_target('go')\n",
    "        arm.go()\n",
    "        gripper.open()\n",
    "        head.set_named_target('neutral')\n",
    "        succ = head.go()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Find_AR_marker(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : Find AR marker ')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        # State Find AR marker\n",
    "        try:\n",
    "            AR_starter.call()\n",
    "            clear_octo_client()\n",
    "        except:\n",
    "            print('cant clear octomap')\n",
    "        #Takeshi looks for AR marker\n",
    "        \n",
    "        rospy.sleep(0.1)\n",
    "        hcp = head.get_current_joint_values()\n",
    "        hcp[0] = 0.5\n",
    "        hcp[1] = -0.2\n",
    "        head.set_joint_value_target(hcp)\n",
    "        head.go()\n",
    "        succ = False\n",
    "        flag = True\n",
    "        talk(\"I am going to find any AR marker\")\n",
    "        rospy.sleep(0.3)\n",
    "        while not succ:\n",
    "            try:\n",
    "                t = tfbuff.lookup_transform('base_link', 'ar_marker/201', rospy.Time(0) )\n",
    "                rospy.sleep(0.3)\n",
    "                trans, _ = tf2_obj_2_arr(t)\n",
    "                distanceX = trans[0]\n",
    "                print(distanceX)\n",
    "                flag = not flag\n",
    "                if distanceX < 0.60 and distanceX > 0.55 and flag:\n",
    "                    hcp = head.get_current_joint_values()\n",
    "                    hcp[0] += 0.4\n",
    "                    hcp[1] = -0.2\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                if distanceX < 0.45:\n",
    "                    succ = True\n",
    "                else:\n",
    "                    grasp_base.tiny_move(velX=0.6,std_time=0.1)\n",
    "            except:\n",
    "                grasp_base.tiny_move(velX=0.5,std_time=0.1)\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "class AR_alignment(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : pre grasp pose ')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        # State AR alignment\n",
    "        succ = False\n",
    "        THRESHOLD = 0.09\n",
    "        hcp = [0.6,-0.1]\n",
    "        flag = True\n",
    "        talk(\"I am going to align with the table\")\n",
    "        while not succ:\n",
    "            try:\n",
    "                t = tfbuff.lookup_transform('base_link','ar_marker/201',rospy.Time(0))\n",
    "                _, rot = tf2_obj_2_arr(t)\n",
    "#     print(rot)\n",
    "                euler = tf.transformations.euler_from_quaternion(rot)\n",
    "                theta = euler[2]\n",
    "                e = theta + 1.57\n",
    "                print(e)\n",
    "#                 if abs(e) < 1.5 and abs(e)>0.6:\n",
    "#                     hcp[0] = 0.3\n",
    "#                     head.set_joint_value_target(hcp)\n",
    "#                     head.go()\n",
    "                if abs(e) < THRESHOLD:\n",
    "                    talk(\"ready\")\n",
    "                    succ = True\n",
    "#                     hcp[0] = 0.4\n",
    "#                     head.set_joint_value_target(hcp)\n",
    "#                     head.go()\n",
    "                else:\n",
    "                    rospy.sleep(0.55)\n",
    "                    grasp_base.tiny_move(velT = 0.2*e, std_time=0.2)\n",
    "                    flag = not flag\n",
    "                    if flag:\n",
    "                        hcp[0] -= 0.1 * (e/abs(e))\n",
    "                        head.set_joint_value_target(hcp)\n",
    "                        head.go()\n",
    "            except:\n",
    "                hcp[0] -= 0.2\n",
    "                if hcp[0] > -1.2:\n",
    "                    hcp[0] = 0.0\n",
    "                head.set_joint_value_target(hcp)\n",
    "                head.go()\n",
    "                \n",
    "        \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "\n",
    "class Pre_grasp_pose(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : pre grasp pose ')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "#         clear_octo_client()\n",
    "        # State Pre grasp pose\n",
    "        succ = False\n",
    "        talk(\"I will reach the cassette\")\n",
    "        gripper.open()\n",
    "        grasp_from_above_joints = [0.59,-1.3376,0,-1.8275,0.0,0.0]\n",
    "        arm.set_joint_value_target(grasp_from_above_joints)\n",
    "        succ = arm.go()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "class AR_adjustment(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : GOTO_SHELF')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3: \n",
    "            return'tries'\n",
    "        # State AR adjustment\n",
    "\n",
    "        try:\n",
    "            clear_octo_client()\n",
    "        except:\n",
    "            print('cant clear octomap')\n",
    "#         scene.remove_world_object()\n",
    "        #Takeshi gets close to the cassette\n",
    "        AR_starter.call()\n",
    "        succ = False\n",
    "        X_OFFSET = 0.0\n",
    "        Y_OFFSET = 0.19\n",
    "        Z_OFFSET = 0.135\n",
    "\n",
    "        THRESHOLD = 0.025\n",
    "\n",
    "        hcp = head.get_current_joint_values()\n",
    "        hcp[0] = -0.1\n",
    "        hcp[1] = -0.5\n",
    "        head.set_joint_value_target(hcp)\n",
    "        head.go()\n",
    "        succ = False\n",
    "        while not succ:\n",
    "            try:\n",
    "                t = tfbuff.lookup_transform('hand_palm_link', 'ar_marker/201', rospy.Time(0) )\n",
    "#         t = tfbuff.lookup_transform('hand_palm_link', 'ar_marker/4000', rospy.Time(0) )\n",
    "                traf = t.transform.translation\n",
    "                rospy.sleep(.6)\n",
    "        # tiny_move_base(y = 0.163)\n",
    "                ex = traf.x + X_OFFSET\n",
    "                ey = -traf.y + Y_OFFSET\n",
    "                print(ex, ey)\n",
    "                if abs(ex) > THRESHOLD:\n",
    "                    grasp_base.tiny_move(velX = ex, MAX_VEL = 0.05)#, y = -traf.y + Y_OFFSET)\n",
    "                if abs(ey) > THRESHOLD:\n",
    "                    grasp_base.tiny_move(velY = ey, MAX_VEL = 0.05)\n",
    "                if (abs(ex) <= THRESHOLD and abs(ey) <= THRESHOLD):\n",
    "                    hcp[0] = 0\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                    talk(\"I am almost there\")\n",
    "                    succ = True\n",
    "            except:\n",
    "                hcp = head.get_current_joint_values()\n",
    "                hcp[0] -= 0.1   \n",
    "                print(hcp[0])\n",
    "                head.set_joint_value_target(hcp)\n",
    "                head.go()\n",
    "                if hcp[0] < -1:\n",
    "                    hcp[0] = 0.1\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                    print('Ive lost the reference')\n",
    "                    succ = False\n",
    "                    break\n",
    "        if succ:\n",
    "            AR_stopper.call()\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "class Color_adjustment(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : color adjustment')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3: \n",
    "            return'tries'\n",
    "        # State color adjustment\n",
    "        try:\n",
    "            clear_octo_client()\n",
    "        except:\n",
    "            print('cant clear octomap')\n",
    "\n",
    "        #Takeshi detects the cassette by color and go for it\n",
    "        succ = False\n",
    "        THRESHOLD = 15\n",
    "        goalPos = [258.61,261.75]\n",
    "        while not succ:\n",
    "            [currentPos] = hand_cam.color_segmentator(color = 'orange')\n",
    "#     print(currentPos)\n",
    "            ex = -(goalPos[0]-currentPos[0]) \n",
    "            ey = (goalPos[1]-currentPos[1])\n",
    "            print(ex, ey)\n",
    "            if abs(ex) > THRESHOLD:\n",
    "                grasp_base.tiny_move(velX = ex, std_time=0.1, MAX_VEL=0.01)#, y = -traf.y + Y_OFFSET)\n",
    "                rospy.sleep(0.5)\n",
    "            if abs(ey) > THRESHOLD:\n",
    "                grasp_base.tiny_move(velY = ey, std_time=0.1, MAX_VEL=0.01)\n",
    "                rospy.sleep(0.5)\n",
    "            if (abs(ex) <= THRESHOLD and abs(ey) <= THRESHOLD):\n",
    "                talk(\"done, now i will take it\")\n",
    "                succ = True\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "    \n",
    "class Grasp_table(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'failed'\n",
    "        # State grasp table\n",
    "        gripper.open()\n",
    "        rospy.sleep(0.3)\n",
    "        acp = [0.56,-1.3376,0,-1.8275,0.0,0.0]\n",
    "        arm.set_joint_value_target(acp)\n",
    "        arm.go()\n",
    "        gripper.close()\n",
    "        rospy.sleep(0.3)\n",
    "        \n",
    "        check_grasp_joints=[0.69,-1.3376,0,-1.8275,0.0,0.0]\n",
    "        arm.set_joint_value_target(check_grasp_joints)\n",
    "        arm.go()\n",
    "        \n",
    "        check_grasp_joints=[0.69,-1.3376,-0.8,-1.8275,0.0,0.0]\n",
    "        arm.set_joint_value_target(check_grasp_joints)\n",
    "        arm.go()\n",
    "\n",
    "        THRESHOLD = 30\n",
    "        goalPos = [233.80,268.74]\n",
    "        [currentPos] = hand_cam.color_segmentator(color = 'orange')\n",
    "        ex = -(goalPos[0]-currentPos[0]) \n",
    "        ey = (goalPos[1]-currentPos[1])\n",
    "        if (abs(ex) <= THRESHOLD and abs(ey) <= THRESHOLD):\n",
    "            talk(\"I have the cassete\")\n",
    "            return 'succ'\n",
    "        else:\n",
    "            talk(\"Something went wrong, i will try again\")\n",
    "            return 'tries'\n",
    "        \n",
    "class Post_grasp_pose(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        # State post grasp pose\n",
    "        acp = arm.get_current_joint_values()\n",
    "        acp[0] = 0.69\n",
    "        arm.set_joint_value_target(acp)\n",
    "        arm.go()\n",
    "        rospy.sleep(0.3)\n",
    "        grasp_base.tiny_move(velX = -0.6, std_time=0.9)\n",
    "        arm.set_named_target('go')\n",
    "        succ = arm.go()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "class Right_shift(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "# State right shift\n",
    "        grasp_base.tiny_move(velY = -0.8, std_time=0.8)\n",
    "        succ = True\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "#Initialize global variables and node\n",
    "def init(node_name):\n",
    "    \n",
    "    global head, whole_body, arm, tfbuff, lis, broad, tf_static_broad\n",
    "    global rgbd, hand_cam, wrist, gripper, grasp_base, clear_octo_client, service_client, AR_starter, AR_stopper\n",
    "\n",
    "    moveit_commander.roscpp_initialize(sys.argv)\n",
    "    rospy.init_node('SMACH_GRAB_CASSETTE')\n",
    "    head = moveit_commander.MoveGroupCommander('head')\n",
    "    whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "    arm =  moveit_commander.MoveGroupCommander('arm')\n",
    "    \n",
    "    tfbuff = tf2.Buffer()\n",
    "    lis = tf2.TransformListener(tfbuff)\n",
    "    broad = tf2.TransformBroadcaster()\n",
    "    tf_static_broad = tf2.StaticTransformBroadcaster()\n",
    "    whole_body.set_workspace([-6.0, -6.0, 6.0, 6.0]) \n",
    "    \n",
    "    rgbd = RGBD()\n",
    "    hand_cam = HAND_RGB()\n",
    "    wrist = WRIST_SENSOR()\n",
    "    gripper = GRIPPER()\n",
    "    grasp_base = OMNIBASE()\n",
    "\n",
    "    clear_octo_client = rospy.ServiceProxy('/clear_octomap', Empty)\n",
    "    AR_starter = rospy.ServiceProxy('/marker/start_recognition',Empty)\n",
    "    AR_stopper = rospy.ServiceProxy('/marker/stop_recognition',Empty)\n",
    "    \n",
    "    head.set_planning_time(0.3)\n",
    "    head.set_num_planning_attempts(1)\n",
    "#Entry point    \n",
    "if __name__== '__main__':\n",
    "    print(\"Takeshi STATE MACHINE...\")\n",
    "    init(\"takeshi_smach_20\")\n",
    "    sm = smach.StateMachine(outcomes = ['END'])     #State machine, final state \"END\"\n",
    "\n",
    "    with sm:\n",
    "        #State machine for grasping on Table\n",
    "        smach.StateMachine.add(\"INITIAL\",Initial(),transitions = {'failed':'INITIAL', 'succ':'FIND_AR_MARKER', 'tries':'END'}) \n",
    "        smach.StateMachine.add(\"FIND_AR_MARKER\",Find_AR_marker(),transitions = {'failed':'END', 'succ':'AR_ALIGNMENT', 'tries':'FIND_AR_MARKER'}) \n",
    "        smach.StateMachine.add(\"AR_ALIGNMENT\",AR_alignment(),transitions = {'failed':'AR_ALIGNMENT', 'succ':'PRE_GRASP_POSE', 'tries':'AR_ALIGNMENT'}) \n",
    "        smach.StateMachine.add(\"PRE_GRASP_POSE\",Pre_grasp_pose(),transitions = {'failed':'RIGHT_SHIFT', 'succ':'AR_ADJUSTMENT', 'tries':'PRE_GRASP_POSE'}) \n",
    "        smach.StateMachine.add(\"RIGHT_SHIFT\",Right_shift(),transitions = {'failed':'RIGHT_SHIFT', 'succ':'PRE_GRASP_POSE', 'tries':'PRE_GRASP_POSE'}) \n",
    "        smach.StateMachine.add(\"AR_ADJUSTMENT\",AR_adjustment(),transitions = {'failed':'END', 'succ':'COLOR_ADJUSTMENT', 'tries':'COLOR_ADJUSTMENT'}) \n",
    "        smach.StateMachine.add(\"COLOR_ADJUSTMENT\",Color_adjustment(),transitions = {'failed':'END', 'succ':'GRASP_TABLE', 'tries':'END'})\n",
    "        smach.StateMachine.add(\"GRASP_TABLE\",Grasp_table(),transitions = {'failed':'END', 'succ':'POST_GRASP_POSE', 'tries':'GRASP_TABLE'})\n",
    "        smach.StateMachine.add(\"POST_GRASP_POSE\",Post_grasp_pose(),transitions = {'failed':'END', 'succ':'END', 'tries':'GRASP_TABLE'})\n",
    "      \n",
    "\n",
    "    outcome = sm.execute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61b095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
