{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91a5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takeshi STATE MACHINE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1663012870.053216997]: Link hand_l_finger_vacuum_frame has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012870.056954918]: Link head_l_stereo_camera_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012870.057090359]: Link head_r_stereo_camera_link has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012870.058282483]: Group state 'neutral' doesn't specify all group joints in group 'arm'. wrist_ft_sensor_frame_joint is missing.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012870.058382402]: Group state 'go' doesn't specify all group joints in group 'arm'. wrist_ft_sensor_frame_joint is missing.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012881.392334402]: Kinematics solver doesn't support #attempts anymore, but only a timeout.\n",
      "Please remove the parameter '/robot_description_kinematics/arm/kinematics_solver_attempts' from your configuration.\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012885.344843628]: IK plugin for group 'whole_body' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012885.765444352]: IK plugin for group 'whole_body_weighted' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n",
      "\u001b[33m[ WARN] [1663012886.144050181]: IK plugin for group 'whole_body_light' relies on deprecated API. Please implement initialize(RobotModel, ...).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ DEBUG ] : Adding state (INITIAL, <__main__.Initial object at 0x7f455816b370>, {'failed': 'INITIAL', 'succ': 'FIND_AR_MARKER', 'tries': 'END'})\n",
      "[ DEBUG ] : Adding state 'INITIAL' to the state machine.\n",
      "[ DEBUG ] : State 'INITIAL' is missing transitions: {}\n",
      "[ DEBUG ] : TRANSITIONS FOR INITIAL: {'failed': 'INITIAL', 'succ': 'FIND_AR_MARKER', 'tries': 'END'}\n",
      "[ DEBUG ] : Adding state (FIND_AR_MARKER, <__main__.Find_AR_marker object at 0x7f455816beb0>, {'failed': 'END', 'succ': 'PRE_GRASP_POSE', 'tries': 'FIND_AR_MARKER'})\n",
      "[ DEBUG ] : Adding state 'FIND_AR_MARKER' to the state machine.\n",
      "[ DEBUG ] : State 'FIND_AR_MARKER' is missing transitions: {}\n",
      "[ DEBUG ] : TRANSITIONS FOR FIND_AR_MARKER: {'failed': 'END', 'succ': 'PRE_GRASP_POSE', 'tries': 'FIND_AR_MARKER'}\n",
      "[ DEBUG ] : Adding state (PRE_GRASP_POSE, <__main__.Pre_grasp_pose object at 0x7f455816b820>, {'failed': 'END', 'succ': 'AR_ADJUSTMENT', 'tries': 'PRE_GRASP_POSE'})\n",
      "[ DEBUG ] : Adding state 'PRE_GRASP_POSE' to the state machine.\n",
      "[ DEBUG ] : State 'PRE_GRASP_POSE' is missing transitions: {}\n",
      "[ DEBUG ] : TRANSITIONS FOR PRE_GRASP_POSE: {'failed': 'END', 'succ': 'AR_ADJUSTMENT', 'tries': 'PRE_GRASP_POSE'}\n",
      "[ DEBUG ] : Adding state (AR_ADJUSTMENT, <__main__.AR_adjustment object at 0x7f455816ba90>, {'failed': 'END', 'succ': 'COLOR_ADJUSTMENT', 'tries': 'COLOR_ADJUSTMENT'})\n",
      "[ DEBUG ] : Adding state 'AR_ADJUSTMENT' to the state machine.\n",
      "[ DEBUG ] : State 'AR_ADJUSTMENT' is missing transitions: {}\n",
      "[ DEBUG ] : TRANSITIONS FOR AR_ADJUSTMENT: {'failed': 'END', 'succ': 'COLOR_ADJUSTMENT', 'tries': 'COLOR_ADJUSTMENT'}\n",
      "[ DEBUG ] : Adding state (COLOR_ADJUSTMENT, <__main__.Color_adjustment object at 0x7f455816b940>, {'failed': 'END', 'succ': 'END', 'tries': 'END'})\n",
      "[ DEBUG ] : Adding state 'COLOR_ADJUSTMENT' to the state machine.\n",
      "[ DEBUG ] : State 'COLOR_ADJUSTMENT' is missing transitions: {}\n",
      "[ DEBUG ] : TRANSITIONS FOR COLOR_ADJUSTMENT: {'failed': 'END', 'succ': 'END', 'tries': 'END'}\n",
      "[  INFO ] : State machine starting in initial state 'INITIAL' with userdata: \n",
      "\t['sm_counter']\n",
      "[INFO] [1663012916.319416]: STATE : robot neutral pose\n",
      "Try 0 of 5 attepmpts\n",
      "[  INFO ] : State machine transitioning 'INITIAL':'succ'-->'FIND_AR_MARKER'\n",
      "[INFO] [1663012927.673276]: State : Find AR marker \n",
      "Try 0 of 5 attepmpts\n",
      "0.8940856375810379\n",
      "0.8940856375810379\n",
      "0.8663422964935427\n",
      "0.8663422964935427\n",
      "0.8416932688002805\n",
      "0.8416932688002805\n",
      "0.8175468556692055\n",
      "0.8175468556692055\n",
      "0.7945944185388867\n",
      "0.7949379675243927\n",
      "0.7949379675243927\n",
      "0.7532235778136964\n",
      "0.7572584227669672\n",
      "0.7458651029666397\n",
      "0.7353785425890251\n",
      "0.7332138120821078\n",
      "0.7332138120821078\n",
      "0.6883171819607175\n",
      "0.6883171819607175\n",
      "0.6545836940936169\n",
      "0.6514179423445207\n",
      "0.6366999756914353\n",
      "0.6327640764588139\n",
      "0.6219754609126097\n",
      "0.6140279553201136\n",
      "0.5967978451032635\n",
      "0.5876618510132579\n",
      "0.5773179817387847\n",
      "0.5703858616464803\n",
      "0.5519882682272105\n",
      "0.5425054107639397\n",
      "0.5249547434948139\n",
      "0.5085878496164166\n",
      "0.4992221167646461\n",
      "0.48138612100517164\n",
      "0.474900700911164\n",
      "0.45962325909404267\n",
      "0.451318312179296\n",
      "0.43434895086242986\n",
      "[  INFO ] : State machine transitioning 'FIND_AR_MARKER':'succ'-->'PRE_GRASP_POSE'\n",
      "[INFO] [1663012962.857055]: State : pre grasp pose \n",
      "Try 0 of 5 attepmpts\n",
      "[  INFO ] : State machine transitioning 'PRE_GRASP_POSE':'succ'-->'AR_ADJUSTMENT'\n",
      "[INFO] [1663012994.819167]: State : GOTO_SHELF\n",
      "Try 0 of 5 attepmpts\n",
      "0.16880338720633847 -0.16949310387591532\n",
      "0.1547882485849793 -0.17484674328518574\n",
      "0.1377035098187922 -0.14347213236948247\n",
      "0.12885151098488457 -0.11944488179740143\n",
      "0.1154665543474922 -0.0961640721713184\n",
      "0.09339392589815265 -0.06774541843952359\n",
      "0.07053788272169537 -0.036639264784278536\n",
      "0.054225720330991156 -0.006691803189131151\n",
      "0.046977217034203766 0.006153053740610981\n",
      "0.034712614484848414 0.01585683374663366\n",
      "0.002420004308593793 0.02230890210726283\n",
      "[  INFO ] : State machine transitioning 'AR_ADJUSTMENT':'succ'-->'COLOR_ADJUSTMENT'\n",
      "[INFO] [1663013025.250587]: State : color adjustment\n",
      "Try 0 of 5 attepmpts\n",
      "-66.91709661806524 138.46044830298263\n",
      "-65.893658225542 138.7435021558268\n",
      "-38.66449487235437 120.09857080514945\n",
      "-17.375674320727853 90.17316024014357\n",
      "14.056935011709584 49.791349531615936\n",
      "27.186538906830776 16.6451922491012\n",
      "11.437882594365988 -32.47088178595857\n",
      "1.919246243189832 -48.04572531880501\n",
      "0.5281844909959545 -46.38983829474461\n",
      "-2.0611032771902273 -25.06068024546289\n",
      "0.24403346483467203 -13.690484287851973\n",
      "done\n",
      "[  INFO ] : State machine terminating 'COLOR_ADJUSTMENT':'succ':'END'\n",
      "shutdown request: new node registered with same name\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from std_srvs.srv import Empty, Trigger, TriggerRequest\n",
    "import smach\n",
    "from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\n",
    "from geometry_msgs.msg import PoseStamped, Point , Quaternion, Twist\n",
    "from actionlib_msgs.msg import GoalStatus\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "import tf2_ros\n",
    "from tf2_sensor_msgs.tf2_sensor_msgs import do_transform_cloud\n",
    "import controller_manager_msgs.srv\n",
    "import rospy\n",
    "import trajectory_msgs.msg\n",
    "import geometry_msgs.msg\n",
    "#from object_classification.srv import *\n",
    "from sensor_msgs.msg import Image as ImageMsg\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from utils_notebooks import *\n",
    "from utils_takeshi import *\n",
    "\n",
    "def color_segmentator(plot = False):\n",
    "    image = hand_cam.get_image()\n",
    "# print(image)\n",
    "# image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    img_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    umbral_bajo = (102,95,97)\n",
    "    umbral_alto = (115,255,255)\n",
    "# hacemos la mask y filtramos en la original\n",
    "    mask = cv2.inRange(img_hsv, umbral_bajo, umbral_alto)\n",
    "    res = cv2.bitwise_and(img_hsv, img_hsv, mask=mask)\n",
    "    if plot:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(res)\n",
    "        plt.show()\n",
    "    pos = []\n",
    "    pixels = cv.findNonZero(mask)\n",
    "#     print([pixels])\n",
    "    pixels = list(cv.mean(pixels))\n",
    "    pos.append(pixels[:2])\n",
    "    return pos\n",
    "def get_line(camera):\n",
    "    if camera == 'hand':\n",
    "         img = hand_cam.get_image()\n",
    "    elif camera == 'head':\n",
    "        img = rgbd.get_image()\n",
    "#     cv.imwrite('table.jpg',img)\n",
    "#     img = cv.imread(cv.samples.findFile('table.jpg'))\n",
    "#     gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    edges = cv.Canny(gray, 50, 150, apertureSize = 3)\n",
    "    lines = cv.HoughLines(edges, 1, np.pi/180,200)\n",
    "#     if len(lines)\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "#         if theta > 0.707 and theta < 2 and (y1 or y2)>480/2:\n",
    "#             cv.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "#     cv.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)    \n",
    "#     cv.imwrite('TableLines.jpg',img)\n",
    "    return lines\n",
    "\n",
    "def tf2_obj_2_arr(transf):\n",
    "    trans = []\n",
    "    trans.append(transf.transform.translation.x)\n",
    "    trans.append(transf.transform.translation.y)\n",
    "    trans.append(transf.transform.translation.z)\n",
    "    \n",
    "    rot = []\n",
    "    rot.append(transf.transform.rotation.x)\n",
    "    rot.append(transf.transform.rotation.y)\n",
    "    rot.append(transf.transform.rotation.z)\n",
    "    rot.append(transf.transform.rotation.w)\n",
    "    \n",
    "    return [trans, rot]\n",
    "    \n",
    "    \n",
    "def correct_points(low_plane=.0,high_plane=0.2):\n",
    "\n",
    "    #Corrects point clouds \"perspective\" i.e. Reference frame head is changed to reference frame map\n",
    "    data = rospy.wait_for_message('/hsrb/head_rgbd_sensor/depth_registered/rectified_points', PointCloud2)\n",
    "    np_data = ros_numpy.numpify(data)\n",
    "    \n",
    "#   new implementation to use only tf2\n",
    "    transf = tfbuff.lookup_transform('map', 'head_rgbd_sensor_gazebo_frame', rospy.Time())\n",
    "    [trans, rot] = tf2_obj_2_arr(transf)\n",
    "    \n",
    "    eu = np.asarray(tf.transformations.euler_from_quaternion(rot))\n",
    "    t = TransformStamped()\n",
    "    rot = tf.transformations.quaternion_from_euler(-eu[1], 0, 0)\n",
    "    t.header.stamp = data.header.stamp\n",
    "    \n",
    "    t.transform.rotation.x = rot[0]\n",
    "    t.transform.rotation.y = rot[1]\n",
    "    t.transform.rotation.z = rot[2]\n",
    "    t.transform.rotation.w = rot[3]\n",
    "\n",
    "    cloud_out = do_transform_cloud(data, t)\n",
    "    np_corrected = ros_numpy.numpify(cloud_out)\n",
    "    corrected = np_corrected.reshape(np_data.shape)\n",
    "\n",
    "    img = np.copy(corrected['y'])\n",
    "\n",
    "    img[np.isnan(img)] = 2\n",
    "    #img3 = np.where((img>low)&(img< 0.99*(trans[2])),img,255)\n",
    "    img3 = np.where((img>0.99*(trans[2])-high_plane)&(img< 0.99*(trans[2])-low_plane),img,255)\n",
    "    return img3\n",
    "\n",
    "def plane_seg_square_imgs(lower=500, higher=50000, reg_ly= 30, reg_hy=600, plt_images=True, low_plane=.0, high_plane=0.2):\n",
    "\n",
    "    #Segment  Plane using corrected point cloud\n",
    "    #Lower, higher = min, max area of the box\n",
    "    #reg_ly= 30,reg_hy=600    Region (low y  region high y ) Only centroids within region are accepted\n",
    "    \n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    img = np.copy(image)\n",
    "    img3 = correct_points(low_plane,high_plane)\n",
    "    \n",
    "#     cv2 on python 3\n",
    "    contours, hierarchy = cv2.findContours(img3.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    points=[]\n",
    "    images=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            img = cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "                image_aux = iimmg[boundRect[1]:boundRect[1]+max(boundRect[2],boundRect[3]),boundRect[0]:boundRect[0]+max(boundRect[2],boundRect[3])]\n",
    "                images.append(image_aux)\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}',    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux = (np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "#                 print (cent)\n",
    "                points.append(xyz)\n",
    "#             else:\n",
    "#                 print ('cent out of region... rejected')\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "           \n",
    "            sub_plt += 1\n",
    "            ax = plt.subplot(5, 5, sub_plt)\n",
    "          \n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents=np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def seg_square_imgs(lower=2000, higher=50000, reg_ly=0, reg_hy=1000, reg_lx=0, reg_hx=1000, plt_images=True): \n",
    "\n",
    "#     Using kmeans for image segmentation find\n",
    "#     Lower, higher = min, max area of the box\n",
    "#     reg_ly= 30,reg_hy=600,reg_lx=0,reg_hx=1000, \n",
    "#     Region (low  x,y  region high x,y ) Only centroids within region are accepted\n",
    "    image = rgbd.get_h_image()\n",
    "    iimmg = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "    values = image.reshape((-1,3))\n",
    "    values = np.float32(values)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k = 6\n",
    "    _ , labels , cc = cv2.kmeans(values, k, None, criteria, 30, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc = np.uint8(cc)\n",
    "    segmented_image = cc[labels.flatten()]\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    im4 = cv2.erode(th3, kernel, iterations = 4)\n",
    "    plane_mask = points_data['z']\n",
    "    cv2_img = plane_mask.astype('uint8')\n",
    "    img = im4\n",
    "    contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    points = []\n",
    "    images = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux = iimmg[boundRect[1]:boundRect[1] + max(boundRect[3],boundRect[2]),boundRect[0]:boundRect[0]+max(boundRect[3],boundRect[2])]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            #img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+max(boundRect[2],boundRect[3]), boundRect[1]+max(boundRect[2],boundRect[3])), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy and  cX > reg_lx and cX < reg_hx   ):\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, f'centroid_{i}_{cX},{cY}', (cX - 25, cY - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                #print ('cX,cY',cX,cY)\n",
    "                xyz = []\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "                xyz = np.asarray(xyz)\n",
    "                cent = xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                #print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                #print ('cent out of region... rejected')\n",
    "                images.pop()\n",
    "    sub_plt = 0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "    cents=np.asarray(cents)\n",
    "    #images.append(img)\n",
    "    return(cents,np.asarray(points), images)\n",
    "\n",
    "def __manipulate_gripper(pos = 0.5, vel = 0.5, effort = 0.2):\n",
    "    grip_cmd_pub = rospy.Publisher('/hsrb/gripper_controller/command',\n",
    "                               trajectory_msgs.msg.JointTrajectory, queue_size=100)\n",
    "    traj = trajectory_msgs.msg.JointTrajectory()\n",
    "    traj.joint_names = [\"hand_motor_joint\"]\n",
    "    p = trajectory_msgs.msg.JointTrajectoryPoint()\n",
    "    p.positions = [pos]\n",
    "    p.velocities = [vel]\n",
    "    p.accelerations = []\n",
    "    p.effort = [effort]\n",
    "    p.time_from_start = rospy.Duration(1)\n",
    "    traj.points = [p]\n",
    "\n",
    "    grip_cmd_pub.publish(traj)\n",
    "\n",
    "def open_gripper(eff=0.5):\n",
    "    __manipulate_gripper(pos=1.23, vel=0.5, effort=eff)\n",
    "    \n",
    "def close_gripper(eff=0.5):\n",
    "    __manipulate_gripper(pos=-0.831, vel=-0.5, effort=-eff)\n",
    "\n",
    "def static_tf_publish(cents):\n",
    "#     Publish tfs of the centroids obtained w.r.t. head sensor frame and references them to map (static)\n",
    "    transf = tfbuff.lookup_transform('map', 'base_link', rospy.Time(0))\n",
    "    [trans, rot] = tf2_obj_2_arr(transf)\n",
    "#     closest_centroid_index=  np.argmin(np.linalg.norm(trans-cents, axis=1))##CLOSEST CENTROID\n",
    "    closest_centroid_index = 0\n",
    "    min_D_to_base = 10\n",
    "    for  i, cent  in enumerate(cents):\n",
    "        x, y, z = cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan')\n",
    "        else:\n",
    "            t = geometry_msgs.msg.TransformStamped()\n",
    "            t.header.stamp = rospy.Time.now()\n",
    "            t.header.frame_id = \"head_rgbd_sensor_link\"\n",
    "            t.child_frame_id = f'Object{i}'\n",
    "            t.transform.translation.x = x\n",
    "            t.transform.translation.y = y\n",
    "            t.transform.translation.z = z\n",
    "            t.transform.rotation.x = rot[0]\n",
    "            t.transform.rotation.y = rot[1]\n",
    "            t.transform.rotation.z = rot[2]\n",
    "            t.transform.rotation.w = rot[3]\n",
    "            broad.sendTransform(t)\n",
    "#             broad.sendTransform((x,y,z), rot, rospy.Time.now(), 'Object'+str(i), \"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(0.5)\n",
    "            transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "            [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "            D_to_base = np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2])\n",
    "            if D_to_base <= min_D_to_base:\n",
    "                min_D_to_base = D_to_base\n",
    "                closest_centroid_index = i\n",
    "                closest_centroid_height = xyz_map[2]\n",
    "            print ('Distance: base to obj - ', i, np.linalg.norm(np.asarray(trans)[:2] - np.asarray(xyz_map)[:2]))\n",
    "    i = closest_centroid_index\n",
    "    transf = tfbuff.lookup_transform('map', f'Object{i}', rospy.Time(0))\n",
    "    [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "    print('Height closest centroid map', xyz_map[2])\n",
    "    map_euler = tf.transformations.euler_from_quaternion(cent_quat)\n",
    "    rospy.sleep(.5)\n",
    "#     FIXING TF TO MAP ( ODOM REALLY)    \n",
    "    static_ts = TransformStamped()\n",
    "    static_ts.header.stamp = rospy.Time.now()\n",
    "    static_ts.header.frame_id = \"map\"\n",
    "    static_ts.child_frame_id = 'cassette'\n",
    "    static_ts.transform.translation.x = float(xyz_map[0])\n",
    "    static_ts.transform.translation.y = float(xyz_map[1])\n",
    "    static_ts.transform.translation.z = float(xyz_map[2])\n",
    "#     quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "    static_ts.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "    static_ts.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "    static_ts.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "    static_ts.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "    print ('xyz_map', xyz_map)\n",
    "    tf_static_broad.sendTransform(static_ts)\n",
    "    return closest_centroid_height, closest_centroid_index\n",
    "\n",
    "def static_publish_ARmarker():\n",
    "    transf = tfbuff.lookup_transform('map', 'ar_marker/201', rospy.Time(0))\n",
    "    [xyz_map, cent_quat] = tf2_obj_2_arr(transf)\n",
    "    print('Height closest centroid map', xyz_map[2])\n",
    "    map_euler = tf.transformations.euler_from_quaternion(cent_quat)\n",
    "    rospy.sleep(.5)\n",
    "#     FIXING TF TO MAP ( ODOM REALLY)    \n",
    "    static_ts = TransformStamped()\n",
    "    static_ts.header.stamp = rospy.Time.now()\n",
    "    static_ts.header.frame_id = \"map\"\n",
    "    static_ts.child_frame_id = 'cassette'\n",
    "    static_ts.transform.translation.x = float(xyz_map[0])\n",
    "    static_ts.transform.translation.y = float(xyz_map[1])\n",
    "    static_ts.transform.translation.z = float(xyz_map[2])\n",
    "#     quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "    static_ts.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "    static_ts.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "    static_ts.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "    static_ts.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "    print ('xyz_map', xyz_map)\n",
    "    tf_static_broad.sendTransform(static_ts)\n",
    "\n",
    "def tiny_move_base(x = 0, y = 0, theta = 0, std_time = 0.5, MAX_VEL = 0.03):\n",
    "    MAX_VEL = 0.03\n",
    "    velX = x/std_time\n",
    "    velY = y/std_time\n",
    "    time = std_time\n",
    "    if abs(velX) > MAX_VEL or abs(velY) > MAX_VEL:\n",
    "        newVelX =  MAX_VEL * np.sign(velX)\n",
    "        newVelY = MAX_VEL * np.sign(velY)\n",
    "#         timeX = x / MAX_VEL\n",
    "#         timeY = y / MAX_VEL\n",
    "#         if timeX > timeY:\n",
    "#             time = timeX\n",
    "#         else:\n",
    "#             time = timeY\n",
    "    else :\n",
    "        newVelX = velX\n",
    "        newVelY = velY\n",
    "    move_base(newVelX, newVelY, theta/std_time, time)\n",
    "\n",
    "def move_base_vel(vx, vy, vw):\n",
    "    twist = Twist()\n",
    "    twist.linear.x = vx\n",
    "    twist.linear.y = vy\n",
    "    twist.angular.z = vw \n",
    "    base_vel_pub.publish(twist)\n",
    "\n",
    "def move_base(x,y,yaw,timeout=0.2):\n",
    "    start_time = rospy.Time.now().to_sec()\n",
    "    while rospy.Time.now().to_sec() - start_time < timeout:  \n",
    "        move_base_vel(x, y, yaw)\n",
    "        \n",
    "def table_alignment():\n",
    "    hcp = head.get_current_joint_values()\n",
    "    hcp[0] = 0.0\n",
    "    hcp[1] = -0.5\n",
    "    head.set_joint_value_target(hcp)\n",
    "    head.go()\n",
    "    threshold = 0.05\n",
    "    while True:\n",
    "        lin = get_line('head')\n",
    "        suma = 0\n",
    "        for el in lin:\n",
    "            suma += el[0][1]\n",
    "        prom = suma / len(lin)\n",
    "        e = 1.5707 - prom\n",
    "        print(e)\n",
    "        if abs(e) < threshold:\n",
    "            break\n",
    "        else:    \n",
    "            move_base(0.0,0.0,0.7*e,0.2)\n",
    "            \n",
    "            ########## Functions for takeshi states ##########\n",
    "class Proto_state(smach.State):###example of a state definition.\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : PROTO_STATE')\n",
    "\n",
    "        if self.tries==3:\n",
    "            self.tries=0 \n",
    "            return'tries'\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        global trans_hand\n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            self.tries=0 \n",
    "            return'tries'\n",
    "   \n",
    "        \n",
    "\n",
    "    ##### Define state INITIAL #####\n",
    "#Estado inicial de takeshi, neutral\n",
    "class Initial(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        \n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        clear_octo_client()\n",
    "        stopper.call()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi neutral\n",
    "        arm.set_named_target('go')\n",
    "        arm.go()\n",
    "        head.set_named_target('neutral')\n",
    "        succ = head.go()\n",
    "        starter.call()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Find_AR_marker(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : Find AR marker ')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi looks for AR marker\n",
    "        hcp = head.get_current_joint_values()\n",
    "        hcp[0]=0.4\n",
    "        hcp[1]= -0.2\n",
    "        head.set_joint_value_target(hcp)\n",
    "        head.go()\n",
    "        succ = False\n",
    "        last = 0\n",
    "        while not succ:\n",
    "            try:\n",
    "                t = tfbuff.lookup_transform('base_link', 'ar_marker/201', rospy.Time(0) )\n",
    "                rospy.sleep(0.3)\n",
    "                trans, _ = tf2_obj_2_arr(t)\n",
    "                print(trans[0])\n",
    "                new = trans[0]\n",
    "                if(last== new):\n",
    "                    hcp = head.get_current_joint_values()\n",
    "                    hcp[0] += 0.1\n",
    "                    hcp[1]= -0.2\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                if trans[0] < 0.45:\n",
    "                    succ = True\n",
    "                else:\n",
    "                    tiny_move_base(x=0.5,std_time=0.1)\n",
    "                last = new\n",
    "            except:\n",
    "                tiny_move_base(x=0.5,std_time=0.1)\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Pre_grasp_pose(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : pre grasp pose ')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        stopper.call()\n",
    "#         clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #static_tf_publish_furniture(-0.95,-0.5,0.0)\n",
    "        tiny_move_base(theta=1.1)\n",
    "        tiny_move_base(theta=1)\n",
    "        tiny_move_base(theta=1.04)\n",
    "        rospy.sleep(0.5)\n",
    "        \n",
    "        grasp_from_above_joints=[0.59,-1.3376,0,-1.8275,0.0,0.0]\n",
    "        arm.set_joint_value_target(grasp_from_above_joints)\n",
    "        succ = arm.go()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "class AR_adjustment(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : GOTO_SHELF')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3: \n",
    "            return'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi gets close to the shelf\n",
    "        starter.call()\n",
    "        succ = False\n",
    "        X_OFFSET = 0.0\n",
    "        Y_OFFSET = 0.19\n",
    "        Z_OFFSET = 0.135\n",
    "\n",
    "        THRESHOLD = 0.025\n",
    "\n",
    "        hcp = head.get_current_joint_values()\n",
    "        hcp[0] = -0.1\n",
    "        hcp[1] = -0.5\n",
    "        head.set_joint_value_target(hcp)\n",
    "        head.go()\n",
    "        while(True):\n",
    "            try:\n",
    "                t = tfbuff.lookup_transform('hand_palm_link', 'ar_marker/201', rospy.Time(0) )\n",
    "#         t = tfbuff.lookup_transform('hand_palm_link', 'ar_marker/4000', rospy.Time(0) )\n",
    "                traf = t.transform.translation\n",
    "                rospy.sleep(.6)\n",
    "        # tiny_move_base(y = 0.163)\n",
    "                ex = x = traf.x + X_OFFSET\n",
    "                ey = -traf.y + Y_OFFSET\n",
    "                print(ex, ey)\n",
    "                if abs(ex) > THRESHOLD:\n",
    "                    tiny_move_base(x = ex)#, y = -traf.y + Y_OFFSET)\n",
    "                if abs(ey) > THRESHOLD:\n",
    "                    tiny_move_base(y = ey)\n",
    "                if (abs(ex) <= THRESHOLD and abs(ey) <= THRESHOLD):\n",
    "                    hcp[0] = 0\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                    succ = True\n",
    "                    break\n",
    "            except:\n",
    "                hcp = head.get_current_joint_values()\n",
    "                hcp[0] -= 0.1   \n",
    "                print(hcp[0])\n",
    "                head.set_joint_value_target(hcp)\n",
    "                head.go()\n",
    "                if hcp[0] < -1:\n",
    "                    hcp[0] = 0.1\n",
    "                    head.set_joint_value_target(hcp)\n",
    "                    head.go()\n",
    "                    print('Ive lost the reference')\n",
    "                    succ = False\n",
    "                    break\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Color_adjustment(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : color adjustment')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3: \n",
    "            return'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi scans the shelf\n",
    "        succ = False\n",
    "        THRESHOLD = 15\n",
    "        while(True):\n",
    "            goalPos = [258.61,261.75]\n",
    "            [currentPos] = color_segmentator()\n",
    "#     print(currentPos)\n",
    "            ex = -(goalPos[0]-currentPos[0]) \n",
    "            ey = (goalPos[1]-currentPos[1])\n",
    "            print(ex, ey)\n",
    "            if abs(ex) > THRESHOLD:\n",
    "                tiny_move_base(x = ex, std_time=0.1, MAX_VEL=0.01)#, y = -traf.y + Y_OFFSET)\n",
    "                rospy.sleep(0.5)\n",
    "            if abs(ey) > THRESHOLD:\n",
    "                tiny_move_base(y = ey, std_time=0.1, MAX_VEL=0.01)\n",
    "                rospy.sleep(0.5)\n",
    "            if (abs(ex) <= THRESHOLD and abs(ey) <= THRESHOLD):\n",
    "                print('done')\n",
    "                succ = True\n",
    "                break\n",
    "\n",
    "        acp = arm.get_current_joint_values()\n",
    "        acp[0] = 0.56\n",
    "        arm.set_joint_value_target(acp)\n",
    "        arm.go()\n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Pre_grasp_shelf(smach.State):###get a convenient pre grasp pose\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : PRE_GRASP_SHELF')\n",
    "        print (\"self.tries\",self.tries)\n",
    "        #target_tf= 'Object_0'\n",
    "        target_tf='Object_1_Table_2'\n",
    "        move_d_to(0.3,target_tf)\n",
    "        head.set_named_target('neutral')\n",
    "        head.go()\n",
    "        arm.set_named_target('neutral')\n",
    "        arm.go()\n",
    "        #move_to_pose_value(posZ=cch)\n",
    "        #open_gripper()      \n",
    "    \n",
    "        pose,quat= listener.lookupTransform('base_link',target_tf,rospy.Time(0))\n",
    "        pose[0]+=-0.15\n",
    "        #pose[1]+= 0.05\n",
    "        broadcaster.sendTransform(pose, quat,rospy.Time.now(),'Pre_grasp','base_link')\n",
    "        rospy.sleep(.1)    \n",
    "     \n",
    "        try:\n",
    "            xyz_map, quat =  listener.lookupTransform('map','Pre_grasp',rospy.Time(0))\n",
    "            print(xyz_map)\n",
    "        except(tf.LookupException):\n",
    "            print ('no pre grasp table2 tf')\n",
    "            self.tries+=1\n",
    "        #return 'failed'\n",
    "        \n",
    "        clear_octo_client()\n",
    "        move_to_pose_value(posZ=xyz_map[2])\n",
    "        open_gripper()\n",
    "        pose=arm.get_current_pose().pose.position\n",
    "        move_to_pose_value(CG=0,posZ=pose.z+0.05,posX=pose.x-0.25)   \n",
    " \n",
    "        try:\n",
    "            xyz_map, quat =  \tlistener.lookupTransform('map','Pre_grasp',rospy.Time(0))\n",
    "            print(xyz_map)\n",
    "            succ = True\n",
    "        except(tf.LookupException):\n",
    "            print ('no pre grasp table2 tf')\n",
    "            self.tries+=1\n",
    "            succ=False\n",
    "        \n",
    "        \n",
    "        clear_octo_client()\n",
    "        move_to_pose_value(posZ=xyz_map[2])\n",
    "        open_gripper()\n",
    "        pose=arm.get_current_pose().pose.position\n",
    "        move_to_pose_value(CG=0,posZ=pose.z+0.05,posX=pose.x-0.25)\n",
    "    \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "       \n",
    "##################################################Pre_grasp_floor()      \n",
    "class Grasp_shelf(smach.State):###example of a state definition.\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'])\n",
    "        self.tries=0\n",
    "    def execute(self,userdata):\n",
    "        rospy.loginfo('State : GRASP_SHELF')\n",
    "        target_tf='Object_1_Table_2'\n",
    "        pose, quat =  listener.lookupTransform('hand_palm_link',target_tf,rospy.Time(0))\n",
    "        print(pose)\n",
    "        while abs(pose[2]) > 0.15:\n",
    "            pose, quat =  listener.lookupTransform('hand_palm_link',target_tf,rospy.Time(0))\n",
    "            #robot_pose = whole_body.get_current_pose().pose.position\n",
    "            #delta =pose[0]-robot_pose.x\n",
    "            #print(delta)\n",
    "            if pose [1] >- 0.2 and pose[1]<0.02:\n",
    "                print ('getting close')\n",
    "                move_abs(0.05,0,0,0.1)\n",
    "            if pose[1] >= 0.02:\n",
    "                print ('drift correct   -')\n",
    "                move_abs(0.0,-0.05,-10, 0.10) \n",
    "            if pose[1] <= -0.02:\n",
    "                print ('drift correct   +')\n",
    "                move_abs(0.0, 0.05,10, 0.10) #GRADOS! WTF , \n",
    "        rospy.sleep(0.1)\n",
    "        clear_octo_client()\n",
    "        #move_to_pose_value(posZ=xyz_map[2])\n",
    "        #open_gripper()\n",
    "        #move_to_pose_value(CG=1,posY=xyz_map[1])\n",
    "        close_gripper()\n",
    "        ajv = arm.get_current_joint_values()\n",
    "        print(ajv)\n",
    "        ajv[4]=-1\n",
    "        move_to_joint_value(ajv)\n",
    "        goal=whole_body.get_current_pose()\n",
    "\n",
    "        move_to_pose_value(posZ=goal.pose.position.z+0.10)\n",
    "        succ=True\n",
    "\n",
    "    \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "\n",
    "class Safe_pos(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "\n",
    "        \n",
    "    def execute(self,userdata):\n",
    "\n",
    "        \n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi neutral\n",
    "        arm.set_named_target('go')\n",
    "        arm.go()\n",
    "        head.set_named_target('neutral')\n",
    "        succ = head.go()             \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "class Goto_play(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "\n",
    "        \n",
    "    def execute(self,userdata):\n",
    "\n",
    "        \n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi neutral\n",
    "        arm.set_named_target('go')\n",
    "        arm.go()\n",
    "        head.set_named_target('neutral')\n",
    "        succ = head.go()             \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "\n",
    "class Leave_cas(smach.State):\n",
    "    def __init__(self):\n",
    "        smach.State.__init__(self,outcomes=['succ','failed','tries'],input_keys=['global_counter'])\n",
    "        self.tries=0\n",
    "\n",
    "        \n",
    "    def execute(self,userdata):\n",
    "\n",
    "        \n",
    "        rospy.loginfo('STATE : robot neutral pose')\n",
    "        print('Try',self.tries,'of 5 attepmpts') \n",
    "        self.tries+=1\n",
    "        if self.tries==3:\n",
    "            return 'tries'\n",
    "        clear_octo_client()\n",
    "        scene.remove_world_object()\n",
    "        #Takeshi neutral\n",
    "        arm.set_named_target('go')\n",
    "        arm.go()\n",
    "        head.set_named_target('neutral')\n",
    "        succ = head.go()             \n",
    "        if succ:\n",
    "            return 'succ'\n",
    "        else:\n",
    "            return 'failed'\n",
    "        \n",
    "#Initialize global variables and node\n",
    "def init(node_name):\n",
    "\n",
    "    global lis, broad, tf_static_broad, tfbuff,scene, rgbd, gripper, head, whole_body, hand_cam\n",
    "    global arm, goal, navclient, clear_octo_client, service_client, base_vel_pub, starter, stopper\n",
    "\n",
    "    moveit_commander.roscpp_initialize(sys.argv)\n",
    "    rospy.init_node('Grab_cassette')\n",
    "    head = moveit_commander.MoveGroupCommander('head')\n",
    "    gripper = moveit_commander.MoveGroupCommander('gripper')\n",
    "    whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "    arm =  moveit_commander.MoveGroupCommander('arm')\n",
    "    \n",
    "    tfbuff = tf2_ros.Buffer()\n",
    "    lis = tf2_ros.TransformListener(tfbuff)\n",
    "    broad = tf2_ros.TransformBroadcaster()\n",
    "    tf_static_broad = tf2_ros.StaticTransformBroadcaster()\n",
    "    whole_body.set_workspace([-6.0, -6.0, 6.0, 6.0]) \n",
    "    \n",
    "    scene = moveit_commander.PlanningSceneInterface()\n",
    "    robot = moveit_commander.RobotCommander()\n",
    "    rgbd = RGBD()\n",
    "    hand_cam = HandRGB()\n",
    "    goal = MoveBaseGoal()\n",
    "    \n",
    "    navclient = actionlib.SimpleActionClient('/move_base/move', MoveBaseAction)\n",
    "    clear_octo_client = rospy.ServiceProxy('/clear_octomap', Empty)\n",
    "    service_client = rospy.ServiceProxy('/segment_2_tf', Trigger)\n",
    "    base_vel_pub = rospy.Publisher('/hsrb/command_velocity', Twist, queue_size=10)\n",
    "    starter = rospy.ServiceProxy('/marker/start_recognition',Empty)\n",
    "    stopper = rospy.ServiceProxy('/marker/stop_recognition',Empty)\n",
    "\n",
    "\n",
    "#Entry point    \n",
    "if __name__== '__main__':\n",
    "    print(\"Takeshi STATE MACHINE...\")\n",
    "    init(\"takeshi_smach_20\")\n",
    "    sm = smach.StateMachine(outcomes = ['END'])     #State machine, final state \"END\"\n",
    "    sm.userdata.sm_counter = 0\n",
    "\n",
    "    with sm:\n",
    "        #State machine for grasping on Floor\n",
    "        smach.StateMachine.add(\"INITIAL\",Initial(),transitions = {'failed':'INITIAL', 'succ':'FIND_AR_MARKER', 'tries':'END'}) \n",
    "        smach.StateMachine.add(\"FIND_AR_MARKER\",Find_AR_marker(),transitions = {'failed':'END', 'succ':'PRE_GRASP_POSE', 'tries':'FIND_AR_MARKER'}) \n",
    "        smach.StateMachine.add(\"PRE_GRASP_POSE\",Pre_grasp_pose(),transitions = {'failed':'END', 'succ':'AR_ADJUSTMENT', 'tries':'PRE_GRASP_POSE'}) \n",
    "        smach.StateMachine.add(\"AR_ADJUSTMENT\",AR_adjustment(),transitions = {'failed':'END', 'succ':'COLOR_ADJUSTMENT', 'tries':'COLOR_ADJUSTMENT'}) \n",
    "        smach.StateMachine.add(\"COLOR_ADJUSTMENT\",Color_adjustment(),transitions = {'failed':'END', 'succ':'END', 'tries':'END'}) \n",
    "\n",
    "      \n",
    "\n",
    "    outcome = sm.execute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d15477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
